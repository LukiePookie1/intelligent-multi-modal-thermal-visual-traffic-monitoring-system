{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461fd0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import xml.etree.ElementTree as ET\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch.nn as nn\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "\n",
    "print(f\"CUDA Available: {cuda_available}\")\n",
    "\n",
    "if cuda_available:\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. PyTorch will use the CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0073802f-a3b0-4578-8549-96784ca4b2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Custom Dataset Class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, split=\"train\", transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.no_annotation_count = 0\n",
    "\n",
    "        images_dir = os.path.join(root_dir, \"raw-images\")\n",
    "        annotations_dir = os.path.join(root_dir, \"annotations\")\n",
    "\n",
    "        for subfolder in os.listdir(images_dir):\n",
    "            subfolder_images_dir = os.path.join(images_dir, subfolder)\n",
    "            subfolder_annotations_dir = os.path.join(annotations_dir, subfolder)\n",
    "\n",
    "            if not os.path.isdir(subfolder_annotations_dir):\n",
    "                continue\n",
    "\n",
    "            image_files = [f for f in os.listdir(subfolder_images_dir) if f.endswith(\".jpg\") or f.endswith(\".png\")]\n",
    "            \n",
    "            image_files = [f for f in image_files if \"rgb\" in f.lower()]\n",
    "\n",
    "            image_files.sort()\n",
    "\n",
    "            num_images = len(image_files)\n",
    "            if split == \"train\":\n",
    "                image_files = image_files[:int(0.7 * num_images)]\n",
    "            elif split == \"val\":\n",
    "                image_files = image_files[int(0.7 * num_images):int(0.9 * num_images)]\n",
    "            elif split == \"test\":\n",
    "                image_files = image_files[int(0.9 * num_images):]\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid split: {split}\")\n",
    "\n",
    "            for filename in image_files:\n",
    "                image_path = os.path.join(subfolder_images_dir, filename)\n",
    "                annotation_path = os.path.join(subfolder_annotations_dir, os.path.splitext(filename)[0] + \".xml\")\n",
    "\n",
    "                if os.path.exists(annotation_path):\n",
    "                    tree = ET.parse(annotation_path)\n",
    "                    root = tree.getroot()\n",
    "                    label = root.find(\"object\").find(\"name\").text\n",
    "\n",
    "                    self.images.append(image_path)\n",
    "                    self.labels.append(label)\n",
    "                else:\n",
    "                    self.no_annotation_count += 1\n",
    "\n",
    "        print(f\"Number of images: {len(self.images)}\")\n",
    "        print(f\"Number of annotations: {len(self.labels)}\")\n",
    "        print(f\"Number of images without annotations: {self.no_annotation_count}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.images[index]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        label = self.labels[index]\n",
    "    \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "    \n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688f3239-66c6-4a54-ab3b-b5b2d7f4912d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Dataset Preparation\n",
    "dataset_path = \"dataset\"\n",
    "split = \"train\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset = CustomDataset(dataset_path, split, transform)\n",
    "\n",
    "class_labels = list(set(dataset.labels))\n",
    "class_to_idx = {label: idx for idx, label in enumerate(class_labels)}\n",
    "print(\"Class labels:\", class_to_idx)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c683722f-bec9-417b-8f5d-49036fe4fdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Model Definition\n",
    "num_classes = len(class_labels)\n",
    "\n",
    "classification_model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "num_features = classification_model.fc.in_features\n",
    "classification_model.fc = nn.Linear(num_features, num_classes)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "classification_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445f044c-e2c2-4a6e-abab-386ec06ae016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Image Classification Training\n",
    "\n",
    "classification_criterion = nn.CrossEntropyLoss()\n",
    "classification_optimizer = torch.optim.AdamW(classification_model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(classification_optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "best_val_accuracy = 0.0\n",
    "best_epoch = 0\n",
    "\n",
    "train_dataset = CustomDataset(dataset_path, split=\"train\", transform=transform)\n",
    "val_dataset = CustomDataset(dataset_path, split=\"val\", transform=transform)\n",
    "test_dataset = CustomDataset(dataset_path, split=\"test\", transform=transform)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    classification_model.train()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for images, labels in train_dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = [class_to_idx[label] for label in labels]\n",
    "        labels = torch.tensor(labels).to(device)\n",
    "        \n",
    "        outputs = classification_model(images)\n",
    "        loss = classification_criterion(outputs, labels)\n",
    "        \n",
    "        classification_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        classification_optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        total_samples += images.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_acc = running_corrects.double() / total_samples\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}\")\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    classification_model.eval()\n",
    "    \n",
    "    val_running_loss = 0.0\n",
    "    val_running_corrects = 0\n",
    "    val_total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for val_images, val_labels in val_dataloader:\n",
    "            val_images = val_images.to(device)\n",
    "            val_labels = [class_to_idx[label] for label in val_labels]\n",
    "            val_labels = torch.tensor(val_labels).to(device)\n",
    "            \n",
    "            val_outputs = classification_model(val_images)\n",
    "            val_loss = classification_criterion(val_outputs, val_labels)\n",
    "            \n",
    "            val_running_loss += val_loss.item() * val_images.size(0)\n",
    "            _, val_preds = torch.max(val_outputs, 1)\n",
    "            val_running_corrects += torch.sum(val_preds == val_labels.data)\n",
    "            val_total_samples += val_images.size(0)\n",
    "    \n",
    "    val_loss = val_running_loss / val_total_samples\n",
    "    val_acc = val_running_corrects.double() / val_total_samples\n",
    "    \n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")\n",
    "    \n",
    "    if val_acc > best_val_accuracy:\n",
    "        best_val_accuracy = val_acc\n",
    "        best_epoch = epoch + 1\n",
    "        torch.save(classification_model.state_dict(), \"best_classification_model.pth\")\n",
    "\n",
    "print(f\"Best Validation Accuracy: {best_val_accuracy:.4f} at Epoch {best_epoch}\")\n",
    "\n",
    "classification_model.load_state_dict(torch.load(\"best_classification_model.pth\"))\n",
    "\n",
    "classification_model.eval()\n",
    "\n",
    "test_running_corrects = 0\n",
    "test_total_samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for test_images, test_labels in test_dataloader:\n",
    "        test_images = test_images.to(device)\n",
    "        test_labels = [class_to_idx[label] for label in test_labels]\n",
    "        test_labels = torch.tensor(test_labels).to(device)\n",
    "        \n",
    "        test_outputs = classification_model(test_images)\n",
    "        _, test_preds = torch.max(test_outputs, 1)\n",
    "        test_running_corrects += torch.sum(test_preds == test_labels.data)\n",
    "        test_total_samples += test_images.size(0)\n",
    "\n",
    "test_acc = test_running_corrects.double() / test_total_samples\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3eda0b-3666-44fe-b7bc-4283f6a080ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Test Image Classification Model\n",
    "\n",
    "loaded_model = models.resnet50()\n",
    "num_features = loaded_model.fc.in_features\n",
    "loaded_model.fc = nn.Linear(num_features, num_classes)\n",
    "loaded_model.load_state_dict(torch.load(\"classification_model.pth\"))\n",
    "loaded_model.to(device)\n",
    "loaded_model.eval()\n",
    "\n",
    "test_dataset = CustomDataset(dataset_path, split=\"test\", transform=transform)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = [class_to_idx[label] for label in labels]\n",
    "        labels = torch.tensor(labels).to(device)\n",
    "        \n",
    "        outputs = loaded_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa58396-5d94-470d-a792-b65d87981f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Visualize Predictions\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "test_dataset = CustomDataset(dataset_path, split=\"test\", transform=transform)\n",
    "random_index = random.randint(0, len(test_dataset) - 1)\n",
    "image, label = test_dataset[random_index]\n",
    "\n",
    "with torch.no_grad():\n",
    "    image = image.unsqueeze(0).to(device)\n",
    "    output = loaded_model(image)\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    predicted_label = class_labels[predicted.item()]\n",
    "\n",
    "plt.imshow(image.squeeze().cpu().permute(1, 2, 0))\n",
    "plt.title(f\"Predicted: {predicted_label}, Actual: {label}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a7a513-04ad-4775-a0e7-597b5e4c39bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Performance Metrics and Visualization\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = [class_to_idx[label] for label in labels]\n",
    "        labels = torch.tensor(labels).to(device)\n",
    "        \n",
    "        outputs = loaded_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "precision = precision_score(true_labels, predictions, average='weighted')\n",
    "recall = recall_score(true_labels, predictions, average='weighted')\n",
    "f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "true_labels_binary = label_binarize(true_labels, classes=range(num_classes))\n",
    "predictions_binary = label_binarize(predictions, classes=range(num_classes))\n",
    "\n",
    "precision_curves = []\n",
    "recall_curves = []\n",
    "avg_precisions = []\n",
    "\n",
    "for i in range(num_classes):\n",
    "    precision_curve, recall_curve, _ = precision_recall_curve(true_labels_binary[:, i], predictions_binary[:, i])\n",
    "    precision_curves.append(precision_curve)\n",
    "    recall_curves.append(recall_curve)\n",
    "    avg_precision = average_precision_score(true_labels_binary[:, i], predictions_binary[:, i])\n",
    "    avg_precisions.append(avg_precision)\n",
    "\n",
    "mean_avg_precision = np.mean(avg_precisions)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(num_classes):\n",
    "    plt.plot(recall_curves[i], precision_curves[i], label=f'Class {i}')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean Average Precision: {mean_avg_precision:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3bc2d2-dd82-4754-abd4-7ac3c540b50a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
