{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba2031e-e444-4ea0-8f0f-9d25d74042fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "\n",
    "input_video = \"raw-traffic-footage/drone-2.mp4\"\n",
    "\n",
    "frames_dir = \"extracted_frames\"\n",
    "os.makedirs(frames_dir, exist_ok=True)\n",
    "\n",
    "video = cv2.VideoCapture(input_video)\n",
    "\n",
    "frame_rate = video.get(cv2.CAP_PROP_FPS)\n",
    "frame_width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "output_video = \"output_video.mp4\"\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "output = cv2.VideoWriter(output_video, fourcc, frame_rate, (frame_width, frame_height))\n",
    "\n",
    "frame_count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame_path = os.path.join(frames_dir, f\"frame_{frame_count:05d}.jpg\")\n",
    "    cv2.imwrite(frame_path, frame)\n",
    "    \n",
    "    frame_count += 1\n",
    "\n",
    "video.release()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = maskrcnn_resnet50_fpn(weights=torchvision.models.detection.MaskRCNN_ResNet50_FPN_Weights.DEFAULT)\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "coco_labels = [\n",
    "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
    "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
    "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
    "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "def detect_objects(image):\n",
    "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "\n",
    "    boxes = outputs[0]['boxes'].cpu().numpy()\n",
    "    labels = outputs[0]['labels'].cpu().numpy()\n",
    "    scores = outputs[0]['scores'].cpu().numpy()\n",
    "    masks = outputs[0]['masks'].cpu().numpy()\n",
    "\n",
    "    detected_objects = []\n",
    "\n",
    "    for box, label, score, mask in zip(boxes, labels, scores, masks):\n",
    "        if score >= 0.5:\n",
    "            detected_objects.append((box, coco_labels[label], score, mask))\n",
    "\n",
    "    return detected_objects\n",
    "\n",
    "def preprocess_image(image_path, target_size=(800, 800)):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    h, w, _ = image.shape\n",
    "    scale = min(target_size[0] / h, target_size[1] / w)\n",
    "    new_size = (int(w * scale), int(h * scale))\n",
    "    \n",
    "    resized_image = cv2.resize(image, new_size)\n",
    "    \n",
    "    padded_image = np.zeros((target_size[0], target_size[1], 3), dtype=np.uint8)\n",
    "    padded_image[:resized_image.shape[0], :resized_image.shape[1], :] = resized_image\n",
    "    \n",
    "    return padded_image, scale, scale\n",
    "\n",
    "def visualize_detections(image_path, detected_objects, scale_x, scale_y, confidence_threshold=0.7):\n",
    "    image = cv2.imread(image_path)\n",
    "    image_with_detections = image.copy()\n",
    "\n",
    "    for box, label, score, _ in detected_objects:\n",
    "        if score >= confidence_threshold:\n",
    "            xmin, ymin, xmax, ymax = box\n",
    "\n",
    "            xmin_adjusted = int(xmin / scale_x)\n",
    "            ymin_adjusted = int(ymin / scale_y)\n",
    "            xmax_adjusted = int(xmax / scale_x)\n",
    "            ymax_adjusted = int(ymax / scale_y)\n",
    "\n",
    "            cv2.rectangle(image_with_detections, (xmin_adjusted, ymin_adjusted), (xmax_adjusted, ymax_adjusted), (0, 255, 0), 2)\n",
    "            cv2.putText(image_with_detections, f\"{label}: {score:.2f}\", (xmin_adjusted, ymin_adjusted - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    return image_with_detections\n",
    "\n",
    "for frame_file in sorted(os.listdir(frames_dir)):\n",
    "    frame_path = os.path.join(frames_dir, frame_file)\n",
    "    \n",
    "    preprocessed_image, scale_x, scale_y = preprocess_image(frame_path)\n",
    "    \n",
    "    pil_image = Image.fromarray(preprocessed_image)\n",
    "    \n",
    "    detected_objects = detect_objects(pil_image)\n",
    "    \n",
    "    image_with_detections = visualize_detections(frame_path, detected_objects, scale_x, scale_y)\n",
    "    \n",
    "    output.write(image_with_detections)\n",
    "\n",
    "output.release()\n",
    "\n",
    "import shutil\n",
    "shutil.rmtree(frames_dir)\n",
    "\n",
    "print(\"Video processing completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07ce878-bb7c-41d8-8ac7-6e1f7c92427e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
