{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05ec6a0-b79d-4095-95fc-79767d1ce54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "\n",
    "print(f\"CUDA Available: {cuda_available}\")\n",
    "\n",
    "if cuda_available:\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. PyTorch will use the CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384b8caf-1504-48d3-848e-1298d71dbbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=torchvision.models.detection.MaskRCNN_ResNet50_FPN_Weights.DEFAULT)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a87893-39c5-4c9e-9c65-3d33b4605796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Define the COCO labels\n",
    "coco_labels = [\n",
    "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
    "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
    "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
    "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]\n",
    "\n",
    "vehicle_labels = ['car', 'motorcycle', 'bus', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48a8b7f-1a5a-49a2-b0b7-b1d434a4fc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Define the transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae6af36-85c8-4423-b85a-192aa1818a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Detect objects in an image\n",
    "def detect_objects(image):\n",
    "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "\n",
    "    boxes = outputs[0]['boxes'].cpu().numpy()\n",
    "    labels = outputs[0]['labels'].cpu().numpy()\n",
    "    scores = outputs[0]['scores'].cpu().numpy()\n",
    "    masks = outputs[0]['masks'].cpu().numpy()\n",
    "\n",
    "    detected_objects = []\n",
    "\n",
    "    for box, label, score, mask in zip(boxes, labels, scores, masks):\n",
    "        if score >= 0.5:\n",
    "            detected_objects.append((box, coco_labels[label], score, mask))\n",
    "\n",
    "    return detected_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32ad030-3a89-4948-b861-60426e825bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_coordinates(box, original_size, preprocessed_size):\n",
    "    original_height, original_width = original_size\n",
    "    preprocessed_height, preprocessed_width = preprocessed_size\n",
    "\n",
    "    y_ratio = original_height / preprocessed_height\n",
    "    x_ratio = original_width / preprocessed_width\n",
    "\n",
    "    xmin, ymin, xmax, ymax = box\n",
    "    xmin = int(xmin * x_ratio)\n",
    "    xmax = int(xmax * x_ratio)\n",
    "    ymin = int(ymin * y_ratio)\n",
    "    ymax = int(ymax * y_ratio)\n",
    "\n",
    "    return xmin, ymin, xmax, ymax\n",
    "\n",
    "def visualize_detections(image_path, detected_objects, scale_x, scale_y, confidence_threshold=0.7):\n",
    "    image = cv2.imread(image_path)\n",
    "    image_with_detections = image.copy()\n",
    "\n",
    "    for box, label, score, _ in detected_objects:\n",
    "        if score >= confidence_threshold:\n",
    "            xmin, ymin, xmax, ymax = box\n",
    "\n",
    "            xmin_adjusted = int(xmin / scale_x)\n",
    "            ymin_adjusted = int(ymin / scale_y)\n",
    "            xmax_adjusted = int(xmax / scale_x)\n",
    "            ymax_adjusted = int(ymax / scale_y)\n",
    "\n",
    "            print(f\"Original Box Coordinates: ({xmin}, {ymin}), ({xmax}, {ymax})\")\n",
    "            print(f\"Adjusted Box Coordinates: ({xmin_adjusted}, {ymin_adjusted}), ({xmax_adjusted}, {ymax_adjusted})\")\n",
    "\n",
    "            cv2.rectangle(image_with_detections, (xmin_adjusted, ymin_adjusted), (xmax_adjusted, ymax_adjusted), (0, 255, 0), 2)\n",
    "            cv2.putText(image_with_detections, f\"{label}: {score:.2f}\", (xmin_adjusted, ymin_adjusted - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    return image_with_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c691e39-1899-49fe-8d54-c020b4bbe68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, target_size=(800, 800)):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    h, w, _ = image.shape\n",
    "    scale = min(target_size[0] / h, target_size[1] / w)\n",
    "    new_size = (int(w * scale), int(h * scale))\n",
    "    \n",
    "    resized_image = cv2.resize(image, new_size)\n",
    "    \n",
    "    padded_image = np.zeros((target_size[0], target_size[1], 3), dtype=np.uint8)\n",
    "    padded_image[:resized_image.shape[0], :resized_image.shape[1], :] = resized_image\n",
    "    \n",
    "    return padded_image, scale, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fce3a65-e66f-46c4-8e4d-8af8e3dc5ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_and_upscale_object(image, box, upscale_factor=4):\n",
    "    xmin, ymin, xmax, ymax = box\n",
    "    cropped_object = image[ymin:ymax, xmin:xmax]\n",
    "    \n",
    "    upscaled_object = cv2.resize(cropped_object, None, fx=upscale_factor, fy=upscale_factor, interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    return upscaled_object\n",
    "\n",
    "os.makedirs(\"cropped-objects\", exist_ok=True)\n",
    "\n",
    "import glob\n",
    "\n",
    "dataset_path = \"dataset/raw-images\"\n",
    "rgb_image_paths = []\n",
    "\n",
    "for subfolder in os.listdir(dataset_path):\n",
    "    if \"rgb\" in subfolder.lower():\n",
    "        subfolder_path = os.path.join(dataset_path, subfolder)\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            rgb_image_paths.extend(glob.glob(os.path.join(subfolder_path, \"*.jpg\")))\n",
    "            rgb_image_paths.extend(glob.glob(os.path.join(subfolder_path, \"*.png\")))\n",
    "\n",
    "np.random.shuffle(rgb_image_paths)\n",
    "\n",
    "num_test_images = 10\n",
    "test_image_paths = rgb_image_paths[:num_test_images]\n",
    "\n",
    "for image_path in test_image_paths:\n",
    "    original_image = cv2.imread(image_path)\n",
    "    preprocessed_image, scale_x, scale_y = preprocess_image(image_path)\n",
    "    print(\"Original Image Shape:\", original_image.shape)\n",
    "    print(\"Preprocessed Image Shape:\", preprocessed_image.shape)\n",
    "    print(\"Scaling Factors: x =\", scale_x, \"y =\", scale_y)\n",
    "    \n",
    "    pil_image = Image.fromarray(preprocessed_image)\n",
    "    \n",
    "    detected_objects = detect_objects(pil_image)\n",
    "    print(\"Detected Objects:\")\n",
    "    for obj in detected_objects:\n",
    "        print(obj)\n",
    "    \n",
    "    for i, (box, label, score, _) in enumerate(detected_objects):\n",
    "        if score >= 0.7:  \n",
    "            xmin, ymin, xmax, ymax = box\n",
    "            xmin_adjusted = int(xmin / scale_x)\n",
    "            ymin_adjusted = int(ymin / scale_y)\n",
    "            xmax_adjusted = int(xmax / scale_x)\n",
    "            ymax_adjusted = int(ymax / scale_y)\n",
    "            \n",
    "            adjusted_box = (xmin_adjusted, ymin_adjusted, xmax_adjusted, ymax_adjusted)\n",
    "            upscaled_object = crop_and_upscale_object(original_image, adjusted_box, upscale_factor=4)\n",
    "            \n",
    "            object_filename = f\"{os.path.splitext(os.path.basename(image_path))[0]}_{i}.jpg\"\n",
    "            object_path = os.path.join(\"cropped-objects\", object_filename)\n",
    "            cv2.imwrite(object_path, upscaled_object)\n",
    "    \n",
    "    image_with_detections = visualize_detections(image_path, detected_objects, scale_x, scale_y)\n",
    "    \n",
    "    print(\"Image with Detections Shape:\", image_with_detections.shape)\n",
    "    \n",
    "    cv2.imshow(\"Image with Detections\", image_with_detections)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1b2754-9d5b-4b02-9181-71dcfd710e40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
