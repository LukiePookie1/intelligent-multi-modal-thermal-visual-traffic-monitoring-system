{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1273a488-0d79-4808-bddc-498341ea3477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import time\n",
    "from scipy.spatial import distance as dist\n",
    "from collections import OrderedDict\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8100c979-b372-4255-a63e-7b7b7088b388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Set up Mask R-CNN model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "mask_rcnn_model = maskrcnn_resnet50_fpn(weights=torchvision.models.detection.MaskRCNN_ResNet50_FPN_Weights.DEFAULT)\n",
    "mask_rcnn_model.to(device)\n",
    "mask_rcnn_model.eval()\n",
    "\n",
    "coco_labels = [\n",
    "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
    "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
    "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
    "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]\n",
    "vehicle_labels = ['car', 'motorcycle', 'bus', 'truck', 'boat']\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "def detect_objects(image):\n",
    "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = mask_rcnn_model(image_tensor)\n",
    "\n",
    "    boxes = outputs[0]['boxes'].cpu().numpy()\n",
    "    labels = outputs[0]['labels'].cpu().numpy()\n",
    "    scores = outputs[0]['scores'].cpu().numpy()\n",
    "    masks = outputs[0]['masks'].cpu().numpy()\n",
    "\n",
    "    detected_objects = []\n",
    "\n",
    "    for box, label, score, mask in zip(boxes, labels, scores, masks):\n",
    "        if score >= 0.7 and label < len(coco_labels) and coco_labels[label] in vehicle_labels:\n",
    "            detected_objects.append((box, coco_labels[label], score, mask))\n",
    "\n",
    "    return detected_objects\n",
    "\n",
    "def preprocess_image(image_path, target_size=(800, 800)):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    h, w, _ = image.shape\n",
    "    scale = min(target_size[0] / h, target_size[1] / w)\n",
    "    new_size = (int(w * scale), int(h * scale))\n",
    "    \n",
    "    resized_image = cv2.resize(image, new_size)\n",
    "    \n",
    "    padded_image = np.zeros((target_size[0], target_size[1], 3), dtype=np.uint8)\n",
    "    padded_image[:resized_image.shape[0], :resized_image.shape[1], :] = resized_image\n",
    "    \n",
    "    return padded_image, scale, scale\n",
    "\n",
    "def visualize_detections(image, detected_objects, scale_x, scale_y, confidence_threshold=0.7):\n",
    "    image_with_detections = image.copy()\n",
    "\n",
    "    for box, label, score, _ in detected_objects:\n",
    "        if score >= confidence_threshold:\n",
    "            xmin, ymin, xmax, ymax = box\n",
    "\n",
    "            xmin_adjusted = int(xmin / scale_x)\n",
    "            ymin_adjusted = int(ymin / scale_y)\n",
    "            xmax_adjusted = int(xmax / scale_x)\n",
    "            ymax_adjusted = int(ymax / scale_y)\n",
    "\n",
    "            cv2.rectangle(image_with_detections, (xmin_adjusted, ymin_adjusted), (xmax_adjusted, ymax_adjusted), (0, 255, 0), 2)\n",
    "            cv2.putText(image_with_detections, f\"{label}: {score:.2f}\", (xmin_adjusted, ymin_adjusted - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    return image_with_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "901ac8ce-7bd1-4ded-a79f-9320a03611ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object detection and congestion report saved to output\\20240409_175726\\detection-and-congestion-report.txt\n",
      "Output video saved to output\\20240409_175726\\output_video.mp4\n",
      "Video processing completed.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Process video and generate object detection report with congestion prediction\n",
    "class CentroidTracker:\n",
    "    def __init__(self, max_disappeared=50):\n",
    "        self.next_object_id = 0\n",
    "        self.objects = OrderedDict()\n",
    "        self.disappeared = OrderedDict()\n",
    "        self.max_disappeared = max_disappeared\n",
    "\n",
    "    def register(self, centroid):\n",
    "        self.objects[self.next_object_id] = centroid\n",
    "        self.disappeared[self.next_object_id] = 0\n",
    "        self.next_object_id += 1\n",
    "\n",
    "    def deregister(self, object_id):\n",
    "        del self.objects[object_id]\n",
    "        del self.disappeared[object_id]\n",
    "\n",
    "    def update(self, rects):\n",
    "        if len(rects) == 0:\n",
    "            for object_id in list(self.disappeared.keys()):\n",
    "                self.disappeared[object_id] += 1\n",
    "                if self.disappeared[object_id] > self.max_disappeared:\n",
    "                    self.deregister(object_id)\n",
    "            return self.objects\n",
    "\n",
    "        input_centroids = np.zeros((len(rects), 2), dtype=\"int\")\n",
    "        for i, (startX, startY, endX, endY) in enumerate(rects):\n",
    "            cX = int((startX + endX) / 2.0)\n",
    "            cY = int((startY + endY) / 2.0)\n",
    "            input_centroids[i] = (cX, cY)\n",
    "\n",
    "        if len(self.objects) == 0:\n",
    "            for i in range(0, len(input_centroids)):\n",
    "                self.register(input_centroids[i])\n",
    "        else:\n",
    "            object_ids = list(self.objects.keys())\n",
    "            object_centroids = list(self.objects.values())\n",
    "\n",
    "            D = dist.cdist(np.array(object_centroids), input_centroids)\n",
    "            rows = D.min(axis=1).argsort()\n",
    "            cols = D.argmin(axis=1)[rows]\n",
    "\n",
    "            used_rows = set()\n",
    "            used_cols = set()\n",
    "\n",
    "            for (row, col) in zip(rows, cols):\n",
    "                if row in used_rows or col in used_cols:\n",
    "                    continue\n",
    "\n",
    "                object_id = object_ids[row]\n",
    "                self.objects[object_id] = input_centroids[col]\n",
    "                self.disappeared[object_id] = 0\n",
    "\n",
    "                used_rows.add(row)\n",
    "                used_cols.add(col)\n",
    "\n",
    "            unused_rows = set(range(0, D.shape[0])).difference(used_rows)\n",
    "            unused_cols = set(range(0, D.shape[1])).difference(used_cols)\n",
    "\n",
    "            if D.shape[0] >= D.shape[1]:\n",
    "                for row in unused_rows:\n",
    "                    object_id = object_ids[row]\n",
    "                    self.disappeared[object_id] += 1\n",
    "\n",
    "                    if self.disappeared[object_id] > self.max_disappeared:\n",
    "                        self.deregister(object_id)\n",
    "            else:\n",
    "                for col in unused_cols:\n",
    "                    self.register(input_centroids[col])\n",
    "\n",
    "        return self.objects\n",
    "\n",
    "def calculate_congestion(objects, frame_width, frame_height):\n",
    "    centroids = list(objects.values())\n",
    "    num_vehicles = len(centroids)\n",
    "\n",
    "    if num_vehicles == 0:\n",
    "        return \"Empty\"\n",
    "\n",
    "    total_distance = 0\n",
    "    num_pairs = 0\n",
    "    for i in range(num_vehicles):\n",
    "        for j in range(i + 1, num_vehicles):\n",
    "            distance = dist.euclidean(centroids[i], centroids[j])\n",
    "            total_distance += distance\n",
    "            num_pairs += 1\n",
    "\n",
    "    if num_pairs > 0:\n",
    "        avg_distance = total_distance / num_pairs\n",
    "    else:\n",
    "        avg_distance = float('inf')\n",
    "\n",
    "    frame_area = frame_width * frame_height\n",
    "    vehicle_density = num_vehicles / frame_area\n",
    "    distance_threshold = min(frame_width, frame_height) * 0.1\n",
    "\n",
    "    if vehicle_density < 0.0001:\n",
    "        return \"Light\"\n",
    "    elif avg_distance > distance_threshold:\n",
    "        return \"Moderate\"\n",
    "    else:\n",
    "        return \"Heavy\"\n",
    "\n",
    "def process_video(input_video):\n",
    "    frames_dir = \"extracted_frames\"\n",
    "    output_video = \"output_video.mp4\"\n",
    "\n",
    "    centroid_tracker = CentroidTracker(max_disappeared=50)\n",
    "\n",
    "    os.makedirs(frames_dir, exist_ok=True)\n",
    "\n",
    "    video = cv2.VideoCapture(input_video)\n",
    "    frame_rate = video.get(cv2.CAP_PROP_FPS)\n",
    "    frame_width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    output = cv2.VideoWriter(output_video, fourcc, frame_rate, (frame_width, frame_height))\n",
    "\n",
    "    frame_count = 0\n",
    "    detection_counts = {}\n",
    "    unique_vehicles = {}\n",
    "    detection_frames = []\n",
    "\n",
    "    global_congestion_counts = {\"Empty\": 0, \"Light\": 0, \"Moderate\": 0, \"Heavy\": 0}\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_path = os.path.join(frames_dir, f\"frame_{frame_count:05d}.jpg\")\n",
    "        cv2.imwrite(frame_path, frame)\n",
    "        \n",
    "        preprocessed_image, scale_x, scale_y = preprocess_image(frame_path)\n",
    "        pil_image = Image.fromarray(preprocessed_image)\n",
    "        detected_objects = detect_objects(pil_image)\n",
    "\n",
    "        rects = []\n",
    "        for box, label, _, _ in detected_objects:\n",
    "            if label in vehicle_labels:\n",
    "                xmin, ymin, xmax, ymax = box\n",
    "                rects.append((xmin, ymin, xmax, ymax))\n",
    "\n",
    "        objects = centroid_tracker.update(rects)\n",
    "\n",
    "        frame_detections = []\n",
    "        for (object_id, _) in objects.items():\n",
    "            for box, label, score, _ in detected_objects:\n",
    "                if label in vehicle_labels:\n",
    "                    if object_id not in unique_vehicles:\n",
    "                        unique_vehicles[object_id] = label\n",
    "                        detection_counts[label] = detection_counts.get(label, 0) + 1\n",
    "                    if unique_vehicles[object_id] == label:\n",
    "                        frame_detections.append((label, score))\n",
    "\n",
    "        detection_frames.append(frame_detections)\n",
    "        \n",
    "        congestion_level = calculate_congestion(objects, frame_width, frame_height)\n",
    "        global_congestion_counts[congestion_level] += 1\n",
    "        \n",
    "        if congestion_level == \"Empty\":\n",
    "            color = (255, 255, 255)  \n",
    "        elif congestion_level == \"Light\":\n",
    "            color = (0, 255, 0)  \n",
    "        elif congestion_level == \"Moderate\":\n",
    "            color = (0, 255, 255) \n",
    "        else:  # \"Heavy\"\n",
    "            color = (0, 0, 255)  \n",
    "        \n",
    "        image_with_detections = visualize_detections(frame, detected_objects, scale_x, scale_y)\n",
    "        cv2.putText(image_with_detections, f\"Congestion: {congestion_level}\", (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "        output.write(image_with_detections)\n",
    "        \n",
    "        frame_count += 1\n",
    "\n",
    "    end_time = time.time()\n",
    "    processing_time = (end_time - start_time) / 60\n",
    "\n",
    "    video.release()\n",
    "    output.release()  \n",
    "\n",
    "    detection_report_lines = [\n",
    "        \"Object Detection and Congestion Report\",\n",
    "        \"======================================\",\n",
    "        \"\",\n",
    "        f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\",\n",
    "        \"\",\n",
    "        f\"Total Frames Analyzed: {frame_count}\",\n",
    "        f\"Processing Time: {processing_time:.2f} minutes\",\n",
    "        \"\",\n",
    "        \"Detection Counts:\",\n",
    "    ]\n",
    "\n",
    "    for label, count in sorted(detection_counts.items()):\n",
    "        detection_report_lines.append(f\"{label}: {count}\")\n",
    "\n",
    "    detection_report_lines.append(\"\")\n",
    "    detection_report_lines.append(\"Congestion Analysis:\")\n",
    "\n",
    "    total_frames = sum(global_congestion_counts.values())\n",
    "    congestion_percentages = {level: count / total_frames for level, count in global_congestion_counts.items()}\n",
    "\n",
    "    for level, percentage in congestion_percentages.items():\n",
    "        detection_report_lines.append(f\"{level}: {percentage:.2%}\")\n",
    "\n",
    "    detection_report_lines.append(\"\")\n",
    "    detection_report_lines.append(\"Global Congestion:\")\n",
    "    global_congestion = max(congestion_percentages, key=congestion_percentages.get)\n",
    "    detection_report_lines.append(f\"{global_congestion}\")\n",
    "\n",
    "    detection_report_lines.append(\"\")\n",
    "    detection_report_lines.append(\"Frame-wise Detections:\")\n",
    "\n",
    "    for frame_idx, frame_detections in enumerate(detection_frames, start=1):\n",
    "        detection_report_lines.append(f\"Frame {frame_idx}:\")\n",
    "        for label, score in frame_detections:\n",
    "            detection_report_lines.append(f\"  - {label}: {score:.2f}\")\n",
    "\n",
    "    detection_report_content = \"\\n\".join(detection_report_lines)\n",
    "\n",
    "    output_dir = \"output\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    timestamped_dir = os.path.join(output_dir, timestamp)\n",
    "    os.makedirs(timestamped_dir, exist_ok=True)\n",
    "\n",
    "    detection_report_file = os.path.join(timestamped_dir, \"detection-and-congestion-report.txt\")\n",
    "    with open(detection_report_file, \"w\") as f:\n",
    "        f.write(detection_report_content)\n",
    "\n",
    "    print(f\"Object detection and congestion report saved to {detection_report_file}\")\n",
    "\n",
    "    output_video_file = os.path.join(timestamped_dir, \"output_video.mp4\")\n",
    "    os.rename(output_video, output_video_file)\n",
    "\n",
    "    print(f\"Output video saved to {output_video_file}\")\n",
    "\n",
    "    shutil.rmtree(frames_dir)\n",
    "\n",
    "    print(\"Video processing completed.\")\n",
    "\n",
    "input_video = \"raw-traffic-footage/bridge-1-rgb.mp4\"\n",
    "process_video(input_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfe0953-c675-4661-b334-f633a1fed8b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71cffa3-efda-4ecf-8f5e-9cdf6390f781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0563d58-f112-439c-aaab-05dd2c61a581",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
