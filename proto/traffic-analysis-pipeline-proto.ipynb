{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67093f5b-08f8-45ce-a0ac-78cb7ed1508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb3ec8f-cb2a-4f7d-b5f1-ec305baa2354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Set up Mask R-CNN model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "mask_rcnn_model = maskrcnn_resnet50_fpn(weights=torchvision.models.detection.MaskRCNN_ResNet50_FPN_Weights.DEFAULT)\n",
    "mask_rcnn_model.to(device)\n",
    "mask_rcnn_model.eval()\n",
    "\n",
    "coco_labels = [\n",
    "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
    "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
    "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
    "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]\n",
    "\n",
    "vehicle_labels = ['car', 'motorcycle', 'bus', 'truck', 'boat']\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "def detect_objects(image):\n",
    "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = mask_rcnn_model(image_tensor)\n",
    "\n",
    "    boxes = outputs[0]['boxes'].cpu().numpy()\n",
    "    labels = outputs[0]['labels'].cpu().numpy()\n",
    "    scores = outputs[0]['scores'].cpu().numpy()\n",
    "    masks = outputs[0]['masks'].cpu().numpy()\n",
    "\n",
    "    detected_objects = []\n",
    "\n",
    "    for box, label, score, mask in zip(boxes, labels, scores, masks):\n",
    "        if score >= 0.7 and coco_labels[label] in vehicle_labels:\n",
    "            detected_objects.append((box, coco_labels[label], score, mask))\n",
    "\n",
    "    return detected_objects\n",
    "\n",
    "def preprocess_image(image_path, target_size=(800, 800)):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    h, w, _ = image.shape\n",
    "    scale = min(target_size[0] / h, target_size[1] / w)\n",
    "    new_size = (int(w * scale), int(h * scale))\n",
    "    \n",
    "    resized_image = cv2.resize(image, new_size)\n",
    "    \n",
    "    padded_image = np.zeros((target_size[0], target_size[1], 3), dtype=np.uint8)\n",
    "    padded_image[:resized_image.shape[0], :resized_image.shape[1], :] = resized_image\n",
    "    \n",
    "    return padded_image, scale, scale\n",
    "\n",
    "def visualize_detections(image, detected_objects, scale_x, scale_y, confidence_threshold=0.7):\n",
    "    image_with_detections = image.copy()\n",
    "\n",
    "    for box, label, score, _ in detected_objects:\n",
    "        if score >= confidence_threshold:\n",
    "            xmin, ymin, xmax, ymax = box\n",
    "\n",
    "            xmin_adjusted = int(xmin / scale_x)\n",
    "            ymin_adjusted = int(ymin / scale_y)\n",
    "            xmax_adjusted = int(xmax / scale_x)\n",
    "            ymax_adjusted = int(ymax / scale_y)\n",
    "\n",
    "            cv2.rectangle(image_with_detections, (xmin_adjusted, ymin_adjusted), (xmax_adjusted, ymax_adjusted), (0, 255, 0), 2)\n",
    "            cv2.putText(image_with_detections, f\"{label}: {score:.2f}\", (xmin_adjusted, ymin_adjusted - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    return image_with_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f9c3ce-768b-4275-9a82-d075bd5becb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Set up ResNet-50 model for classification\n",
    "def upscale_and_enhance(image):\n",
    "    desired_size = (256, 256)  \n",
    "    upscaled_image = image.resize(desired_size, Image.LANCZOS)\n",
    "    return upscaled_image \n",
    "    \n",
    "preprocess_classification = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: upscale_and_enhance(img)),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "def preprocess_image_classification(image_path):\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img_t = preprocess(img)\n",
    "    return img_t\n",
    "\n",
    "resnet_model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "resnet_model.eval()\n",
    "\n",
    "def classify_image(image_path, model, preprocess, imagenet_labels, classification_counts, image_predictions):\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    \n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')  \n",
    "    plt.show()\n",
    "\n",
    "    img_t = preprocess(img)\n",
    "    batch_t = torch.unsqueeze(img_t, 0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model(batch_t)\n",
    "    probabilities = torch.nn.functional.softmax(out[0], dim=0)\n",
    "    top1_prob, top1_catid = torch.topk(probabilities, 1)\n",
    "    \n",
    "    if top1_prob[0].item() >= 0.7:  # Check if the confidence score is at least 0.7\n",
    "        class_label = imagenet_labels[top1_catid[0].item()]\n",
    "        print(f\"Image: {os.path.basename(image_path)}\")\n",
    "        print(f\"Predicted Class: {class_label} - {top1_prob[0].item()}\")\n",
    "        classification_counts[class_label] = classification_counts.get(class_label, 0) + 1\n",
    "        image_predictions[os.path.basename(image_path)] = (class_label, top1_prob[0].item())\n",
    "\n",
    "    return classification_counts, image_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab2a73e-5a4c-4fa8-958b-3635d68669f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Cell 4: Process video and generate classification report\n",
    "def process_video(input_video, imagenet_labels_json):\n",
    "    frames_dir = \"extracted_frames\"\n",
    "    cropped_images_dir = 'cropped-objects'\n",
    "    output_video = \"output_video.mp4\"\n",
    "\n",
    "    os.makedirs(frames_dir, exist_ok=True)\n",
    "    os.makedirs(cropped_images_dir, exist_ok=True)\n",
    "\n",
    "    video = cv2.VideoCapture(input_video)\n",
    "    frame_rate = video.get(cv2.CAP_PROP_FPS)\n",
    "    frame_width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    output = cv2.VideoWriter(output_video, fourcc, frame_rate, (frame_width, frame_height))\n",
    "\n",
    "    frame_count = 0\n",
    "    save_interval = int(frame_rate * 3)  \n",
    "    total_images = 0  \n",
    "\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_path = os.path.join(frames_dir, f\"frame_{frame_count:05d}.jpg\")\n",
    "        cv2.imwrite(frame_path, frame)\n",
    "        \n",
    "        if frame_count % save_interval == 0:  \n",
    "            preprocessed_image, scale_x, scale_y = preprocess_image(frame_path)\n",
    "            pil_image = Image.fromarray(preprocessed_image)\n",
    "            detected_objects = detect_objects(pil_image)\n",
    "            \n",
    "            for i, (box, label, score, _) in enumerate(detected_objects):\n",
    "                if label in vehicle_labels: \n",
    "                    xmin, ymin, xmax, ymax = box\n",
    "                    xmin_adjusted = int(xmin / scale_x)\n",
    "                    ymin_adjusted = int(ymin / scale_y)\n",
    "                    xmax_adjusted = int(xmax / scale_x)\n",
    "                    ymax_adjusted = int(ymax / scale_y)\n",
    "                    \n",
    "                    adjusted_box = (xmin_adjusted, ymin_adjusted, xmax_adjusted, ymax_adjusted)\n",
    "                    cropped_object = frame[ymin_adjusted:ymax_adjusted, xmin_adjusted:xmax_adjusted]\n",
    "                    \n",
    "                    if cropped_object.size > 0:  \n",
    "                        object_filename = f\"{os.path.splitext(os.path.basename(frame_path))[0]}_{i}.jpg\"\n",
    "                        object_path = os.path.join(cropped_images_dir, object_filename)\n",
    "                        cv2.imwrite(object_path, cropped_object)\n",
    "                        total_images += 1  \n",
    "        \n",
    "        image_with_detections = visualize_detections(frame, detected_objects, scale_x, scale_y)\n",
    "        output.write(image_with_detections)\n",
    "        \n",
    "        frame_count += 1\n",
    "\n",
    "    video.release()\n",
    "    output.release()\n",
    "\n",
    "    with open(imagenet_labels_json, 'r') as f:\n",
    "        imagenet_labels = json.load(f)\n",
    "\n",
    "    classification_counts = {}\n",
    "    image_predictions = {}\n",
    "    detection_counts = {}\n",
    "\n",
    "    for image_file in os.listdir(cropped_images_dir):\n",
    "        image_path = os.path.join(cropped_images_dir, image_file)\n",
    "        classification_counts, image_predictions = classify_image(image_path, resnet_model, preprocess_classification, imagenet_labels, classification_counts, image_predictions)\n",
    "\n",
    "    classification_report_lines = [\n",
    "        \"Image Classification Report\",\n",
    "        \"===========================\",\n",
    "        \"\",\n",
    "        f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\",\n",
    "        \"\",\n",
    "        f\"Total Images Viewed: {total_images}\",\n",
    "        \"\",\n",
    "        \"Classification Counts:\",\n",
    "    ]\n",
    "\n",
    "    for class_label, count in sorted(classification_counts.items()):\n",
    "        classification_report_lines.append(f\"{class_label}: {count}\")\n",
    "\n",
    "    classification_report_lines.append(\"\")\n",
    "    classification_report_lines.append(\"Image Predictions:\")\n",
    "\n",
    "    for image_name, (class_label, confidence_score) in image_predictions.items():\n",
    "        classification_report_lines.append(f\"{image_name}\")\n",
    "        classification_report_lines.append(f\"  Predicted Class: {class_label}\")\n",
    "        classification_report_lines.append(f\"  Confidence Score: {confidence_score:.4f}\")\n",
    "        classification_report_lines.append(\"\")\n",
    "\n",
    "    classification_report_content = \"\\n\".join(classification_report_lines)\n",
    "\n",
    "    detection_report_lines = [\n",
    "        \"Object Detection Report\",\n",
    "        \"=======================\",\n",
    "        \"\",\n",
    "        f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\",\n",
    "        \"\",\n",
    "        \"Detection Counts:\",\n",
    "    ]\n",
    "\n",
    "    for label, count in sorted(detection_counts.items()):\n",
    "        detection_report_lines.append(f\"{label}: {count}\")\n",
    "\n",
    "    detection_report_content = \"\\n\".join(detection_report_lines)\n",
    "\n",
    "    output_dir = \"output\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    timestamped_dir = os.path.join(output_dir, timestamp)\n",
    "    os.makedirs(timestamped_dir, exist_ok=True)\n",
    "\n",
    "    classification_report_file = os.path.join(timestamped_dir, \"classification-report.txt\")\n",
    "    with open(classification_report_file, \"w\") as f:\n",
    "        f.write(classification_report_content)\n",
    "\n",
    "    print(f\"Classification report saved to {classification_report_file}\")\n",
    "\n",
    "    detection_report_file = os.path.join(timestamped_dir, \"detection-report.txt\")\n",
    "    with open(detection_report_file, \"w\") as f:\n",
    "        f.write(detection_report_content)\n",
    "\n",
    "    print(f\"Object detection report saved to {detection_report_file}\")\n",
    "\n",
    "    output_video_file = os.path.join(timestamped_dir, \"output_video.mp4\")\n",
    "    os.rename(output_video, output_video_file)\n",
    "\n",
    "    print(f\"Output video saved to {output_video_file}\")\n",
    "\n",
    "    shutil.rmtree(frames_dir)\n",
    "    shutil.rmtree(cropped_images_dir)\n",
    "\n",
    "    print(\"Video processing completed.\")\n",
    "\n",
    "input_video = \"raw-traffic-footage/bridge-1-rgb-test.mp4\"\n",
    "imagenet_labels_json = 'imagenet-simple-labels.json'\n",
    "\n",
    "process_video(input_video, imagenet_labels_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f2d309-93fa-4d57-85bb-e89fc238119a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889a82e2-2d56-4a9b-948e-b570d8100d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e777ff7b-f07a-4eee-8212-d219b2f034f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eada1b1-154a-46ca-93bb-3fb260ebfddc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f62669c-3ce5-4907-8097-e8eba3086166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b98f39-3560-4efc-8a69-351c29b16064",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
