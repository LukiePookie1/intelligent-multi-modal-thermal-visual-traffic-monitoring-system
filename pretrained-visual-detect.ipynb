{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40bacdaf-828d-4550-a60f-fb9c161d436d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "GPU 0: NVIDIA GeForce RTX 3080\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "\n",
    "print(f\"CUDA Available: {cuda_available}\")\n",
    "\n",
    "if cuda_available:\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. PyTorch will use the CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c50b885f-ddb4-44f7-8a62-ad94f9d46f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0-3): 4 x Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=91, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=364, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 2: Load the pre-trained model\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=torchvision.models.detection.FasterRCNN_ResNet50_FPN_Weights.DEFAULT)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6bf9fb9a-7d58-48fa-ac56-cb863c02083d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Define the COCO labels\n",
    "coco_labels = [\n",
    "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
    "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
    "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
    "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]\n",
    "\n",
    "vehicle_labels = ['car', 'motorcycle', 'bus', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb256a50-0d30-4a6b-b479-6a5e92852bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Define the transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1468e706-ea6f-4ac7-8380-78691e46eab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Detect objects in an image\n",
    "def detect_objects(image):\n",
    "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "\n",
    "    boxes = outputs[0]['boxes'].cpu().numpy()\n",
    "    labels = outputs[0]['labels'].cpu().numpy()\n",
    "    scores = outputs[0]['scores'].cpu().numpy()\n",
    "\n",
    "    detected_objects = []\n",
    "\n",
    "    for box, label, score in zip(boxes, labels, scores):\n",
    "        if score >= 0.5:\n",
    "            detected_objects.append((box, coco_labels[label], score))\n",
    "\n",
    "    return detected_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "086e9558-210e-4b49-b386-4c043c4952a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_coordinates(box, original_size, preprocessed_size):\n",
    "    original_width, original_height = original_size\n",
    "    preprocessed_width, preprocessed_height = preprocessed_size\n",
    "\n",
    "    scale_width = original_width / preprocessed_width\n",
    "    scale_height = original_height / preprocessed_height\n",
    "\n",
    "    xmin, ymin, xmax, ymax = box\n",
    "    xmin = int(xmin * scale_width)\n",
    "    xmax = int(xmax * scale_width)\n",
    "    ymin = int(ymin * scale_height)\n",
    "    ymax = int(ymax * scale_height)\n",
    "\n",
    "    return xmin, ymin, xmax, ymax\n",
    "\n",
    "def visualize_detections(image_path, detected_objects, preprocessed_image, confidence_threshold=0.7):\n",
    "    image = cv2.imread(image_path)\n",
    "    image_with_detections = image.copy()\n",
    "\n",
    "    original_size = (image.shape[1], image.shape[0])  # (width, height)\n",
    "    preprocessed_size = (preprocessed_image.shape[1], preprocessed_image.shape[0])  # (width, height)\n",
    "\n",
    "    for box, label, score in detected_objects:\n",
    "        if score >= confidence_threshold:\n",
    "            adjusted_box = adjust_coordinates(box, original_size, preprocessed_size)\n",
    "            xmin, ymin, xmax, ymax = adjusted_box\n",
    "\n",
    "            cv2.rectangle(image_with_detections, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "            cv2.putText(image_with_detections, f\"{label}: {score:.2f}\", (xmin, ymin - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    return image_with_detections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2166b955-071a-4dec-b384-1187b68095f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Preprocess the image\n",
    "def preprocess_image(image_path, target_size=(800, 800)):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    h, w, _ = image.shape\n",
    "    scale = min(target_size[0] / w, target_size[1] / h)\n",
    "    resized_image = cv2.resize(image, None, fx=scale, fy=scale)\n",
    "    \n",
    "    padded_image = np.zeros((target_size[0], target_size[1], 3), dtype=np.uint8)\n",
    "    h, w, _ = resized_image.shape\n",
    "    padded_image[:h, :w, :] = resized_image\n",
    "    \n",
    "    return padded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "600cf7c7-556b-4c55-934b-32982b3ddab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed Image Shape: (800, 800, 3)\n",
      "Detected Objects:\n",
      "Image with Detections Shape: (480, 640, 3)\n",
      "Preprocessed Image Shape: (800, 800, 3)\n",
      "Detected Objects:\n",
      "(array([  0.     ,   0.     , 749.33997, 431.07166], dtype=float32), 'tv', 0.5689711)\n",
      "Image with Detections Shape: (480, 640, 3)\n",
      "Preprocessed Image Shape: (800, 800, 3)\n",
      "Detected Objects:\n",
      "Image with Detections Shape: (480, 640, 3)\n",
      "Preprocessed Image Shape: (800, 800, 3)\n",
      "Detected Objects:\n",
      "Image with Detections Shape: (480, 640, 3)\n",
      "Preprocessed Image Shape: (800, 800, 3)\n",
      "Detected Objects:\n",
      "(array([6.7153931e-01, 1.6996796e+01, 8.0000000e+02, 6.1201453e+02],\n",
      "      dtype=float32), 'tv', 0.62913007)\n",
      "Image with Detections Shape: (480, 640, 3)\n",
      "Preprocessed Image Shape: (800, 800, 3)\n",
      "Detected Objects:\n",
      "(array([  4.5536194,  10.750214 , 800.       , 587.2853   ], dtype=float32), 'tv', 0.6369719)\n",
      "Image with Detections Shape: (480, 640, 3)\n",
      "Preprocessed Image Shape: (800, 800, 3)\n",
      "Detected Objects:\n",
      "(array([601.5782 , 215.01357, 800.     , 541.64874], dtype=float32), 'person', 0.7529108)\n",
      "Image with Detections Shape: (480, 640, 3)\n",
      "Preprocessed Image Shape: (800, 800, 3)\n",
      "Detected Objects:\n",
      "(array([168.60065,  91.06324, 334.07312, 184.22668], dtype=float32), 'donut', 0.80227745)\n",
      "(array([673.67114, 157.53032, 800.     , 273.56192], dtype=float32), 'car', 0.67170256)\n",
      "(array([167.6    ,  89.37091, 334.0629 , 181.19061], dtype=float32), 'car', 0.55774784)\n",
      "Image with Detections Shape: (480, 640, 3)\n",
      "Preprocessed Image Shape: (800, 800, 3)\n",
      "Detected Objects:\n",
      "(array([ 42.84076,  22.93753, 800.     , 577.8096 ], dtype=float32), 'clock', 0.52011347)\n",
      "Image with Detections Shape: (480, 640, 3)\n",
      "Preprocessed Image Shape: (800, 800, 3)\n",
      "Detected Objects:\n",
      "Image with Detections Shape: (480, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Test object detection with preprocessing\n",
    "import glob\n",
    "\n",
    "dataset_path = \"dataset/raw-images\"\n",
    "rgb_image_paths = []\n",
    "\n",
    "for subfolder in os.listdir(dataset_path):\n",
    "    if \"drone-1\" in subfolder.lower():\n",
    "        subfolder_path = os.path.join(dataset_path, subfolder)\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            rgb_image_paths.extend(glob.glob(os.path.join(subfolder_path, \"*.jpg\")))\n",
    "            rgb_image_paths.extend(glob.glob(os.path.join(subfolder_path, \"*.png\")))\n",
    "\n",
    "np.random.shuffle(rgb_image_paths)\n",
    "\n",
    "num_test_images = 10\n",
    "test_image_paths = rgb_image_paths[:num_test_images]\n",
    "\n",
    "# Perform object detection on the test images with preprocessing\n",
    "for image_path in test_image_paths:\n",
    "    original_image = cv2.imread(image_path)\n",
    "    preprocessed_image = preprocess_image(image_path)\n",
    "    print(\"Preprocessed Image Shape:\", preprocessed_image.shape)\n",
    "    \n",
    "    pil_image = Image.fromarray(preprocessed_image)\n",
    "    \n",
    "    detected_objects = detect_objects(pil_image)\n",
    "    print(\"Detected Objects:\")\n",
    "    for obj in detected_objects:\n",
    "        print(obj)\n",
    "    \n",
    "    scale_x = original_image.shape[1] / preprocessed_image.shape[1]\n",
    "    scale_y = original_image.shape[0] / preprocessed_image.shape[0]\n",
    "    \n",
    "    image_with_detections = original_image.copy()\n",
    "    \n",
    "    for box, label, score in detected_objects:\n",
    "        if score >= 0.5:\n",
    "            xmin, ymin, xmax, ymax = box\n",
    "            xmin_scaled = int(xmin * scale_x)\n",
    "            ymin_scaled = int(ymin * scale_y)\n",
    "            xmax_scaled = int(xmax * scale_x)\n",
    "            ymax_scaled = int(ymax * scale_y)\n",
    "            \n",
    "            cv2.rectangle(image_with_detections, (xmin_scaled, ymin_scaled), (xmax_scaled, ymax_scaled), (0, 255, 0), 2)\n",
    "            cv2.putText(image_with_detections, f\"{label}: {score:.2f}\", (xmin_scaled, ymin_scaled - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "    \n",
    "    print(\"Image with Detections Shape:\", image_with_detections.shape)\n",
    "    \n",
    "    cv2.imshow(\"Image with Detections\", image_with_detections)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c54f279-bf3f-4b9b-9fc6-1a6f1c8abaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed Image Shape: (800, 800, 3)\n",
      "Detected Objects:\n",
      "(array([179.58846, 196.14975, 215.99614, 223.22278], dtype=float32), 'car', 0.91898793)\n",
      "(array([337.58514, 291.103  , 442.9649 , 386.80032], dtype=float32), 'car', 0.9118417)\n",
      "(array([ 92.586754, 160.43011 , 112.469   , 175.68536 ], dtype=float32), 'car', 0.905757)\n",
      "(array([111.77837, 176.77052, 144.04596, 202.4291 ], dtype=float32), 'car', 0.88266915)\n",
      "(array([339.37158, 158.58626, 364.5572 , 175.9634 ], dtype=float32), 'car', 0.71888435)\n",
      "(array([110.75403 , 148.30756 , 125.597855, 159.67328 ], dtype=float32), 'car', 0.6997602)\n",
      "(array([ 68.10623, 130.91238,  82.57922, 138.95792], dtype=float32), 'car', 0.6139918)\n",
      "(array([ 92.290634, 141.79918 , 109.26984 , 152.61986 ], dtype=float32), 'car', 0.59994316)\n",
      "(array([111.93699, 178.23132, 129.29147, 201.71869], dtype=float32), 'car', 0.5916819)\n",
      "(array([335.84955, 151.22008, 364.62518, 174.78764], dtype=float32), 'truck', 0.5691566)\n",
      "Image with Detections Shape: (720, 1280, 3)\n",
      "Preprocessed Image Shape: (800, 800, 3)\n",
      "Detected Objects:\n",
      "(array([642.6745 , 167.88249, 707.0705 , 205.36769], dtype=float32), 'car', 0.993749)\n",
      "(array([442.5933  ,  93.40645 , 466.00943 , 108.438934], dtype=float32), 'car', 0.97631025)\n",
      "(array([400.71252 ,  74.419395, 422.87793 ,  92.86628 ], dtype=float32), 'car', 0.9621668)\n",
      "(array([361.9032 ,  66.09478, 379.71185,  80.28651], dtype=float32), 'car', 0.635904)\n",
      "(array([212.84894 ,  75.73464 , 230.17993 ,  90.561775], dtype=float32), 'car', 0.54057914)\n",
      "Image with Detections Shape: (720, 1280, 3)\n",
      "Preprocessed Image Shape: (800, 800, 3)\n",
      "Detected Objects:\n",
      "(array([424.82556, 102.52184, 442.16553, 114.69669], dtype=float32), 'car', 0.59496945)\n",
      "Image with Detections Shape: (720, 1280, 3)\n",
      "Preprocessed Image Shape: (800, 800, 3)\n",
      "Detected Objects:\n",
      "(array([139.56013, 136.31314, 166.62062, 161.70215], dtype=float32), 'car', 0.95973235)\n",
      "(array([402.1058 , 106.63573, 510.25912, 158.20195], dtype=float32), 'truck', 0.9362766)\n",
      "(array([629.95654, 171.78026, 642.11804, 188.614  ], dtype=float32), 'fire hydrant', 0.7820003)\n",
      "(array([ 84.438156,  76.731735, 111.241516, 101.0556  ], dtype=float32), 'car', 0.69826555)\n",
      "(array([758.4484 , 199.92728, 771.88617, 219.44995], dtype=float32), 'fire hydrant', 0.689877)\n",
      "(array([118.967735,  94.01912 , 136.71878 , 106.144226], dtype=float32), 'car', 0.68456763)\n",
      "Image with Detections Shape: (720, 1280, 3)\n",
      "Preprocessed Image Shape: (800, 800, 3)\n",
      "Detected Objects:\n",
      "(array([494.45435, 324.58054, 515.9362 , 339.43698], dtype=float32), 'car', 0.76939964)\n",
      "(array([219.44983 ,  61.72708 , 238.94153 ,  83.782684], dtype=float32), 'car', 0.6700764)\n",
      "Image with Detections Shape: (720, 1280, 3)\n",
      "Preprocessed Image Shape: (800, 800, 3)\n",
      "Detected Objects:\n",
      "(array([277.07565, 137.26642, 335.76712, 171.04742], dtype=float32), 'truck', 0.97684026)\n",
      "(array([387.7153 , 181.7097 , 427.72092, 202.60884], dtype=float32), 'car', 0.93913084)\n",
      "(array([226.04402, 149.24403, 243.38313, 159.42177], dtype=float32), 'car', 0.815802)\n",
      "(array([129.18457, 204.53493, 163.96146, 238.90059], dtype=float32), 'car', 0.7983729)\n",
      "(array([714.1004 , 233.21515, 742.62506, 249.07959], dtype=float32), 'car', 0.79121643)\n",
      "(array([572.5657 , 204.59262, 583.5565 , 218.97827], dtype=float32), 'fire hydrant', 0.76126117)\n",
      "(array([130.20865, 211.25829, 149.66681, 236.447  ], dtype=float32), 'car', 0.65965366)\n",
      "Image with Detections Shape: (720, 1280, 3)\n",
      "Preprocessed Image Shape: (800, 800, 3)\n",
      "Detected Objects:\n",
      "(array([253.96219, 102.36051, 278.61838, 129.61354], dtype=float32), 'car', 0.95436054)\n",
      "(array([201.72212,  86.23552, 251.43044, 166.80008], dtype=float32), 'truck', 0.82499504)\n",
      "Image with Detections Shape: (720, 1280, 3)\n",
      "Preprocessed Image Shape: (800, 800, 3)\n",
      "Detected Objects:\n",
      "(array([ 94.31333, 176.48436, 119.08485, 197.77187], dtype=float32), 'car', 0.7502517)\n",
      "(array([249.2792 , 147.78761, 263.22775, 157.96559], dtype=float32), 'car', 0.63399833)\n",
      "(array([176.58379, 134.4079 , 200.85146, 146.10898], dtype=float32), 'car', 0.5964813)\n",
      "Image with Detections Shape: (720, 1280, 3)\n",
      "Preprocessed Image Shape: (800, 800, 3)\n",
      "Detected Objects:\n",
      "(array([402.91202, 127.02773, 431.02505, 142.49005], dtype=float32), 'car', 0.92988974)\n",
      "(array([757.3024 , 199.72887, 772.26154, 219.54958], dtype=float32), 'fire hydrant', 0.9232489)\n",
      "(array([165.49048, 124.37793, 187.95676, 141.55792], dtype=float32), 'car', 0.90400076)\n",
      "(array([309.80704, 109.93187, 329.58823, 122.72409], dtype=float32), 'car', 0.8959091)\n",
      "(array([238.97835, 168.40234, 282.09534, 191.86652], dtype=float32), 'car', 0.81978303)\n",
      "(array([542.06696, 175.79066, 596.1419 , 194.3456 ], dtype=float32), 'car', 0.7841021)\n",
      "(array([397.41837 , 124.255356, 422.8182  , 140.91035 ], dtype=float32), 'car', 0.6304954)\n",
      "(array([629.55273, 170.8184 , 641.34204, 188.13585], dtype=float32), 'fire hydrant', 0.62469155)\n",
      "(array([390.84677, 121.28047, 403.4055 , 130.93408], dtype=float32), 'car', 0.6121752)\n",
      "(array([475.9058 , 136.8763 , 485.8494 , 152.07552], dtype=float32), 'person', 0.6113655)\n",
      "(array([216.71588, 172.91516, 258.58127, 199.3259 ], dtype=float32), 'car', 0.6036999)\n",
      "(array([113.59963,  94.25422, 164.401  , 156.76102], dtype=float32), 'bus', 0.56696504)\n",
      "(array([412.9833 , 129.85555, 430.2297 , 142.75722], dtype=float32), 'car', 0.55827117)\n",
      "(array([218.378  , 163.69221, 278.4599 , 214.09074], dtype=float32), 'car', 0.54953545)\n",
      "Image with Detections Shape: (720, 1280, 3)\n",
      "Preprocessed Image Shape: (800, 800, 3)\n",
      "Detected Objects:\n",
      "(array([184.28967, 209.75462, 236.98279, 274.5258 ], dtype=float32), 'car', 0.96666884)\n",
      "(array([256.78412, 125.34684, 279.09778, 146.3865 ], dtype=float32), 'car', 0.9642754)\n",
      "(array([217.48486, 111.66307, 238.3887 , 129.43428], dtype=float32), 'car', 0.91662127)\n",
      "(array([248.50304, 107.72684, 268.08783, 124.46062], dtype=float32), 'car', 0.9060601)\n",
      "(array([293.44907, 215.60733, 344.88034, 266.79733], dtype=float32), 'car', 0.78257036)\n",
      "(array([247.78653 , 117.253044, 278.36417 , 145.23569 ], dtype=float32), 'car', 0.6871675)\n",
      "Image with Detections Shape: (720, 1280, 3)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf504f9-9968-4719-be1f-49fc08c5a57e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
