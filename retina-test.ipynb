{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72a1b057-3fde-4b55-a5ae-415c3832ac17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "GPU 0: NVIDIA GeForce RTX 3080\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "\n",
    "print(f\"CUDA Available: {cuda_available}\")\n",
    "\n",
    "if cuda_available:\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. PyTorch will use the CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7d89ef0-9c89-42a9-9143-c51a936e9058",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucas\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lucas\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=RetinaNet_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=RetinaNet_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RetinaNet(\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0-2): 3 x Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (extra_blocks): LastLevelP6P7(\n",
       "        (p6): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (anchor_generator): AnchorGenerator()\n",
       "  (head): RetinaNetHead(\n",
       "    (classification_head): RetinaNetClassificationHead(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cls_logits): Conv2d(256, 819, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (regression_head): RetinaNetRegressionHead(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (bbox_reg): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 2: Load the pre-trained RetinaNet model\n",
    "model = torchvision.models.detection.retinanet_resnet50_fpn(pretrained=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "079540a1-b913-466f-8117-0f046b7bb350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Define the COCO labels\n",
    "coco_labels = [\n",
    "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
    "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
    "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
    "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]\n",
    "\n",
    "vehicle_labels = ['car', 'motorcycle', 'bus', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af908e59-19f0-405a-9b98-4b76844c3b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Define the transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13b38985-b289-4a09-bec5-436f29d0e7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Detect objects in an image\n",
    "def detect_objects(image):\n",
    "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "\n",
    "    boxes = outputs[0]['boxes'].cpu().numpy()\n",
    "    labels = outputs[0]['labels'].cpu().numpy()\n",
    "    scores = outputs[0]['scores'].cpu().numpy()\n",
    "\n",
    "    detected_objects = []\n",
    "\n",
    "    for box, label, score in zip(boxes, labels, scores):\n",
    "        if score >= 0.5:\n",
    "            detected_objects.append((box, coco_labels[label], score))\n",
    "\n",
    "    return detected_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c288b08e-e561-4644-9dfc-c54068840060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_coordinates(box, original_size, preprocessed_size):\n",
    "    original_width, original_height = original_size\n",
    "    preprocessed_width, preprocessed_height = preprocessed_size\n",
    "\n",
    "    scale_width = original_width / preprocessed_width\n",
    "    scale_height = original_height / preprocessed_height\n",
    "\n",
    "    xmin, ymin, xmax, ymax = box\n",
    "    xmin = int(xmin * scale_width)\n",
    "    xmax = int(xmax * scale_width)\n",
    "    ymin = int(ymin * scale_height)\n",
    "    ymax = int(ymax * scale_height)\n",
    "\n",
    "    return xmin, ymin, xmax, ymax\n",
    "\n",
    "def visualize_detections(image_path, detected_objects, preprocessed_image, confidence_threshold=0.7):\n",
    "    image = cv2.imread(image_path)\n",
    "    image_with_detections = image.copy()\n",
    "\n",
    "    original_size = (image.shape[1], image.shape[0])  # (width, height)\n",
    "    preprocessed_size = (preprocessed_image.shape[1], preprocessed_image.shape[0])  # (width, height)\n",
    "\n",
    "    for box, label, score in detected_objects:\n",
    "        if score >= confidence_threshold:\n",
    "            adjusted_box = adjust_coordinates(box, original_size, preprocessed_size)\n",
    "            xmin, ymin, xmax, ymax = adjusted_box\n",
    "\n",
    "            cv2.rectangle(image_with_detections, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "            cv2.putText(image_with_detections, f\"{label}: {score:.2f}\", (xmin, ymin - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    return image_with_detections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c5d1eac-03c3-4d97-9643-b59b69dc13fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Preprocess the image\n",
    "def preprocess_image(image_path, target_size=(800, 800)):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    h, w, _ = image.shape\n",
    "    scale = min(target_size[0] / w, target_size[1] / h)\n",
    "    resized_image = cv2.resize(image, None, fx=scale, fy=scale)\n",
    "    \n",
    "    padded_image = np.zeros((target_size[0], target_size[1], 3), dtype=np.uint8)\n",
    "    h, w, _ = resized_image.shape\n",
    "    padded_image[:h, :w, :] = resized_image\n",
    "    \n",
    "    return padded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59969e4b-9674-49aa-9222-42075a37d016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed Image Shape: (800, 800, 3)\n",
      "Detected Objects:\n",
      "Image with Detections Shape: (720, 1280, 3)\n",
      "Preprocessed Image Shape: (800, 800, 3)\n",
      "Detected Objects:\n",
      "(array([151.84396, 122.1436 , 294.6679 , 313.85718], dtype=float32), 'train', 0.76169896)\n",
      "(array([576.03015, 169.4619 , 633.444  , 195.84962], dtype=float32), 'car', 0.67914516)\n",
      "(array([381.1723 , 130.26294, 402.87695, 144.52979], dtype=float32), 'car', 0.572196)\n",
      "(array([101.06355,  92.8962 , 133.27386, 131.2688 ], dtype=float32), 'car', 0.5034947)\n",
      "Image with Detections Shape: (720, 1280, 3)\n",
      "Preprocessed Image Shape: (800, 800, 3)\n",
      "Detected Objects:\n",
      "(array([140.24258, 154.71288, 165.87854, 179.33263], dtype=float32), 'car', 0.66215444)\n",
      "(array([165.60815, 138.05038, 191.26547, 158.57187], dtype=float32), 'car', 0.53653294)\n",
      "Image with Detections Shape: (720, 1280, 3)\n",
      "Preprocessed Image Shape: (800, 800, 3)\n",
      "Detected Objects:\n",
      "(array([567.453  , 153.69333, 765.041  , 231.83661], dtype=float32), 'truck', 0.62256265)\n",
      "(array([144.90263, 161.03833, 264.56583, 318.51645], dtype=float32), 'train', 0.58761895)\n",
      "Image with Detections Shape: (720, 1280, 3)\n",
      "Preprocessed Image Shape: (800, 800, 3)\n",
      "Detected Objects:\n",
      "(array([274.90482, 266.49478, 335.05838, 316.3992 ], dtype=float32), 'car', 0.74526703)\n",
      "(array([104.36363, 146.18625, 159.29881, 217.03372], dtype=float32), 'truck', 0.7301537)\n",
      "(array([309.77438, 149.63713, 329.30942, 160.31001], dtype=float32), 'car', 0.5172044)\n",
      "Image with Detections Shape: (720, 1280, 3)\n",
      "Preprocessed Image Shape: (800, 800, 3)\n",
      "Detected Objects:\n",
      "(array([214.61296, 132.94427, 250.88759, 162.776  ], dtype=float32), 'car', 0.7640476)\n",
      "(array([  9.290039,   8.950882, 691.22833 , 458.6576  ], dtype=float32), 'train', 0.6853215)\n",
      "Image with Detections Shape: (720, 1280, 3)\n",
      "Preprocessed Image Shape: (800, 800, 3)\n",
      "Detected Objects:\n",
      "(array([229.03423, 187.02736, 272.3247 , 214.16075], dtype=float32), 'car', 0.7833514)\n",
      "(array([558.95886, 178.22128, 611.26465, 202.69193], dtype=float32), 'car', 0.6990499)\n",
      "(array([130.17801, 124.50264, 188.10062, 197.94746], dtype=float32), 'bus', 0.65215605)\n",
      "(array([130.17801, 124.50264, 188.10062, 197.94746], dtype=float32), 'truck', 0.50750136)\n",
      "Image with Detections Shape: (720, 1280, 3)\n",
      "Preprocessed Image Shape: (800, 800, 3)\n",
      "Detected Objects:\n",
      "(array([229.57857, 163.7135 , 275.13452, 192.26547], dtype=float32), 'car', 0.8402011)\n",
      "(array([351.3274 , 247.0911 , 433.6136 , 315.44046], dtype=float32), 'car', 0.80039155)\n",
      "(array([109.08732,  88.47493, 179.30917, 168.90117], dtype=float32), 'bus', 0.6311666)\n",
      "(array([173.27155, 113.18157, 202.88559, 139.59529], dtype=float32), 'car', 0.51841396)\n",
      "Image with Detections Shape: (720, 1280, 3)\n",
      "Preprocessed Image Shape: (800, 800, 3)\n",
      "Detected Objects:\n",
      "(array([518.38   , 180.58127, 571.0737 , 207.00809], dtype=float32), 'car', 0.81601274)\n",
      "(array([132.12248, 223.69655, 187.23964, 274.34454], dtype=float32), 'car', 0.78539085)\n",
      "Image with Detections Shape: (720, 1280, 3)\n",
      "Preprocessed Image Shape: (800, 800, 3)\n",
      "Detected Objects:\n",
      "Image with Detections Shape: (720, 1280, 3)\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Test object detection with preprocessing\n",
    "import glob\n",
    "\n",
    "dataset_path = \"raw-images\"\n",
    "rgb_image_paths = []\n",
    "\n",
    "for subfolder in os.listdir(dataset_path):\n",
    "    if \"rgb\" in subfolder.lower():\n",
    "        subfolder_path = os.path.join(dataset_path, subfolder)\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            rgb_image_paths.extend(glob.glob(os.path.join(subfolder_path, \"*.jpg\")))\n",
    "            rgb_image_paths.extend(glob.glob(os.path.join(subfolder_path, \"*.png\")))\n",
    "\n",
    "np.random.shuffle(rgb_image_paths)\n",
    "\n",
    "num_test_images = 10\n",
    "test_image_paths = rgb_image_paths[:num_test_images]\n",
    "\n",
    "for image_path in test_image_paths:\n",
    "    original_image = cv2.imread(image_path)\n",
    "    preprocessed_image = preprocess_image(image_path)\n",
    "    print(\"Preprocessed Image Shape:\", preprocessed_image.shape)\n",
    "    \n",
    "    pil_image = Image.fromarray(preprocessed_image)\n",
    "    \n",
    "    detected_objects = detect_objects(pil_image)\n",
    "    print(\"Detected Objects:\")\n",
    "    for obj in detected_objects:\n",
    "        print(obj)\n",
    "    \n",
    "    scale_x = original_image.shape[1] / preprocessed_image.shape[1]\n",
    "    scale_y = original_image.shape[0] / preprocessed_image.shape[0]\n",
    "    \n",
    "    image_with_detections = original_image.copy()\n",
    "    \n",
    "    for box, label, score in detected_objects:\n",
    "        if score >= 0.5:\n",
    "            xmin, ymin, xmax, ymax = box\n",
    "            xmin_scaled = int(xmin * scale_x)\n",
    "            ymin_scaled = int(ymin * scale_y)\n",
    "            xmax_scaled = int(xmax * scale_x)\n",
    "            ymax_scaled = int(ymax * scale_y)\n",
    "            \n",
    "            cv2.rectangle(image_with_detections, (xmin_scaled, ymin_scaled), (xmax_scaled, ymax_scaled), (0, 255, 0), 2)\n",
    "            cv2.putText(image_with_detections, f\"{label}: {score:.2f}\", (xmin_scaled, ymin_scaled - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "    \n",
    "    print(\"Image with Detections Shape:\", image_with_detections.shape)\n",
    "    \n",
    "    cv2.imshow(\"Image with Detections\", image_with_detections)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f347c1-b264-4586-9148-3621a6216675",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
