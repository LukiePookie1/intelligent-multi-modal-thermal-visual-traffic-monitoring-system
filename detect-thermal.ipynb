{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165b528f-67f8-479a-bbdf-192f9e13dc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import xml.etree.ElementTree as ET\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch.nn as nn\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "\n",
    "print(f\"CUDA Available: {cuda_available}\")\n",
    "\n",
    "if cuda_available:\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. PyTorch will use the CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ed462c-91e2-4f8b-9890-23be5d1b1131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Custom Dataset Class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, split=\"train\", transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.annotations = []\n",
    "        self.no_annotation_count = 0\n",
    "\n",
    "        images_dir = os.path.join(root_dir, \"raw-images\")\n",
    "        annotations_dir = os.path.join(root_dir, \"annotations\")\n",
    "\n",
    "        for subfolder in os.listdir(images_dir):\n",
    "            subfolder_images_dir = os.path.join(images_dir, subfolder)\n",
    "            subfolder_annotations_dir = os.path.join(annotations_dir, subfolder)\n",
    "\n",
    "            if not os.path.isdir(subfolder_annotations_dir):\n",
    "                continue\n",
    "\n",
    "            image_files = [f for f in os.listdir(subfolder_images_dir) if f.endswith(\".jpg\") or f.endswith(\".png\")]\n",
    "\n",
    "            image_files.sort()\n",
    "\n",
    "            num_images = len(image_files)\n",
    "            if split == \"train\":\n",
    "                image_files = image_files[:int(0.7 * num_images)]\n",
    "            elif split == \"val\":\n",
    "                image_files = image_files[int(0.7 * num_images):int(0.9 * num_images)]\n",
    "            elif split == \"test\":\n",
    "                image_files = image_files[int(0.9 * num_images):]\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid split: {split}\")\n",
    "\n",
    "            for filename in image_files:\n",
    "                image_path = os.path.join(subfolder_images_dir, filename)\n",
    "                annotation_path = os.path.join(subfolder_annotations_dir, os.path.splitext(filename)[0] + \".xml\")\n",
    "\n",
    "                if os.path.exists(annotation_path):\n",
    "                    tree = ET.parse(annotation_path)\n",
    "                    root = tree.getroot()\n",
    "                    annotation = []\n",
    "\n",
    "                    for obj in root.findall(\"object\"):\n",
    "                        name = obj.find(\"name\").text\n",
    "                        bbox = obj.find(\"bndbox\")\n",
    "                        xmin = int(bbox.find(\"xmin\").text)\n",
    "                        ymin = int(bbox.find(\"ymin\").text)\n",
    "                        xmax = int(bbox.find(\"xmax\").text)\n",
    "                        ymax = int(bbox.find(\"ymax\").text)\n",
    "                        annotation.append((xmin, ymin, xmax, ymax))\n",
    "\n",
    "                    self.images.append(image_path)\n",
    "                    self.annotations.append(annotation)\n",
    "                else:\n",
    "                    self.no_annotation_count += 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.images[index]\n",
    "        image = Image.open(image_path).convert(\"L\")\n",
    "        annotation = self.annotations[index]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if annotation is not None:\n",
    "            boxes = torch.as_tensor(annotation, dtype=torch.float32)\n",
    "            labels = torch.ones((len(annotation),), dtype=torch.int64)\n",
    "        else:\n",
    "            boxes = torch.empty((0, 4), dtype=torch.float32)\n",
    "            labels = torch.empty((0,), dtype=torch.int64)\n",
    "\n",
    "        return image, {\"boxes\": boxes, \"labels\": labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd8803b-ad51-490f-a357-b248ab6b1749",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Test the dataset\n",
    "dataset_path = \"dataset\"  \n",
    "split = \"train\"  \n",
    "thermal_transform = transforms.Compose([\n",
    "    transforms.Resize((800, 800)),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "thermal_dataset = CustomDataset(dataset_path, split, thermal_transform)\n",
    "print(f\"Number of images in the dataset: {len(thermal_dataset)}\")\n",
    "image, target = thermal_dataset[0]\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "print(f\"Target boxes: {target['boxes']}\")\n",
    "print(f\"Target labels: {target['labels']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22f6551-03b4-49ce-aa75-28c340899847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Dataset Preprocessing\n",
    "def preprocess_dataset(dataset):\n",
    "    preprocessed_images = []\n",
    "    preprocessed_annotations = []\n",
    "    \n",
    "    for image, target in dataset:\n",
    "        if isinstance(image, torch.Tensor):\n",
    "            image = transforms.ToPILImage()(image)\n",
    "        else:\n",
    "            image = Image.fromarray(image)\n",
    "        \n",
    "        image = thermal_transform(image)\n",
    "        \n",
    "        boxes = target['boxes']\n",
    "        labels = target['labels']\n",
    "        \n",
    "        _, height, width = image.shape\n",
    "        boxes[:, [0, 2]] /= width\n",
    "        boxes[:, [1, 3]] /= height\n",
    "        \n",
    "        target = {'boxes': boxes, 'labels': labels}\n",
    "        \n",
    "        preprocessed_images.append(image)\n",
    "        preprocessed_annotations.append(target)\n",
    "    \n",
    "    return preprocessed_images, preprocessed_annotations\n",
    "\n",
    "# Test the preprocessing function\n",
    "dataset_path = \"dataset\"\n",
    "split = \"train\"\n",
    "thermal_dataset = CustomDataset(dataset_path, split=split, transform=thermal_transform)\n",
    "preprocessed_images, preprocessed_annotations = preprocess_dataset(thermal_dataset)\n",
    "print(f\"Number of preprocessed images: {len(preprocessed_images)}\")\n",
    "print(f\"Number of preprocessed annotations: {len(preprocessed_annotations)}\")\n",
    "print(f\"Preprocessed image shape: {preprocessed_images[0].shape}\")\n",
    "print(f\"Preprocessed annotation boxes shape: {preprocessed_annotations[0]['boxes'].shape}\")\n",
    "print(f\"Preprocessed annotation labels shape: {preprocessed_annotations[0]['labels'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba4709a-4bfd-47cb-b4fb-13313163cb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Dataset and DataLoader Creation\n",
    "dataset_path = \"dataset\"\n",
    "split = \"train\"\n",
    "\n",
    "thermal_transform = transforms.Compose([\n",
    "    transforms.Resize((800, 800)),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "thermal_dataset = CustomDataset(dataset_path, split, thermal_transform)\n",
    "\n",
    "class_labels = set()\n",
    "for _, annotation in thermal_dataset:\n",
    "    for obj in annotation:\n",
    "        name = obj[0]\n",
    "        class_labels.add(\"vehicle\")  \n",
    "\n",
    "class_to_idx = {\"vehicle\": 0}  \n",
    "print(\"Class labels:\", class_to_idx)\n",
    "\n",
    "preprocessed_thermal_images, preprocessed_thermal_annotations = preprocess_dataset(thermal_dataset)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images = [item[0] for item in batch]\n",
    "    targets = [item[1] for item in batch]\n",
    "    \n",
    "    images = torch.stack(images, dim=0)\n",
    "    \n",
    "    return images, targets\n",
    "\n",
    "train_thermal_dataset = list(zip(preprocessed_thermal_images, preprocessed_thermal_annotations))\n",
    "train_thermal_loader = DataLoader(train_thermal_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "for images, targets in train_thermal_loader:\n",
    "    print(f\"Batch images shape: {images.shape}\")\n",
    "    print(f\"Batch targets boxes shape: {targets[0]['boxes'].shape}\")\n",
    "    print(f\"Batch targets labels shape: {targets[0]['labels'].shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c6623a-9064-4031-ac93-d852c0ddb78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Model Definition and Training\n",
    "num_classes = len(class_to_idx) + 1\n",
    "\n",
    "thermal_model = fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "in_features = thermal_model.roi_heads.box_predictor.cls_score.in_features\n",
    "thermal_model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "thermal_model.to(device)\n",
    "\n",
    "thermal_optimizer = torch.optim.SGD(thermal_model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "num_epochs = 30\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    thermal_model.train()\n",
    "    \n",
    "    thermal_epoch_loss = 0.0\n",
    "    \n",
    "    for thermal_images, thermal_targets in train_thermal_loader:\n",
    "        thermal_images = list(image.to(device) for image in thermal_images)\n",
    "        thermal_targets = [{k: v.to(device) for k, v in t.items()} for t in thermal_targets]\n",
    "        \n",
    "        thermal_loss_dict = thermal_model(thermal_images, thermal_targets)\n",
    "        thermal_losses = sum(loss for loss in thermal_loss_dict.values())\n",
    "        \n",
    "        thermal_optimizer.zero_grad()\n",
    "        thermal_losses.backward()\n",
    "        thermal_optimizer.step()\n",
    "        \n",
    "        thermal_epoch_loss += thermal_losses.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Thermal Loss: {thermal_epoch_loss/len(train_thermal_loader):.4f}\")\n",
    "\n",
    "torch.save(thermal_model.state_dict(), \"trained_model.pth\")\n",
    "\n",
    "thermal_model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, targets in train_thermal_loader:\n",
    "        images = list(image.to(device) for image in images)\n",
    "        outputs = thermal_model(images)\n",
    "        \n",
    "        for i in range(len(images)):\n",
    "            boxes = outputs[i]['boxes'].cpu().numpy()\n",
    "            labels = outputs[i]['labels'].cpu().numpy()\n",
    "            scores = outputs[i]['scores'].cpu().numpy()\n",
    "            \n",
    "            print(f\"Image {i+1} - Boxes: {boxes}, Labels: {labels}, Scores: {scores}\")\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b54a6a-d4d1-4a78-ae65-202639ddfcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Evaluation and Testing\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, targets in dataloader:\n",
    "            images = list(image.to(device) for image in images)\n",
    "            outputs = model(images)\n",
    "            \n",
    "            for output in outputs:\n",
    "                boxes = output['boxes'].cpu().numpy()\n",
    "                labels = output['labels'].cpu().numpy()\n",
    "                scores = output['scores'].cpu().numpy()\n",
    "                \n",
    "                indices = torchvision.ops.nms(torch.tensor(boxes), torch.tensor(scores), iou_threshold=0.5)\n",
    "                \n",
    "                filtered_boxes = boxes[indices]\n",
    "                filtered_labels = labels[indices]\n",
    "                filtered_scores = scores[indices]\n",
    "                \n",
    "                all_predictions.append((filtered_boxes, filtered_labels, filtered_scores))\n",
    "            \n",
    "            for target in targets:\n",
    "                boxes = target['boxes'].cpu().numpy()\n",
    "                labels = target['labels'].cpu().numpy()\n",
    "                \n",
    "                all_targets.append((boxes, labels))\n",
    "    \n",
    "    return all_predictions, all_targets\n",
    "\n",
    "test_split = \"test\"\n",
    "test_thermal_dataset = CustomDataset(dataset_path, test_split, thermal_transform)\n",
    "test_thermal_loader = DataLoader(test_thermal_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "test_predictions, test_targets = evaluate_model(thermal_model, test_thermal_loader, device)\n",
    "print(f\"Number of test predictions: {len(test_predictions)}\")\n",
    "print(f\"Number of test targets: {len(test_targets)}\")\n",
    "print(f\"Test prediction boxes shape: {test_predictions[0][0].shape}\")\n",
    "print(f\"Test prediction labels shape: {test_predictions[0][1].shape}\")\n",
    "print(f\"Test prediction scores shape: {test_predictions[0][2].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ba4cbe-2489-43b6-8927-980eabef9771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Load the trained model\n",
    "thermal_model.load_state_dict(torch.load(\"trained_model.pth\"))\n",
    "thermal_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc26e762-2ad1-4d30-aabe-95c025616211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Prepare the test dataset\n",
    "test_split = \"test\"\n",
    "test_thermal_dataset = CustomDataset(dataset_path, test_split, thermal_transform)\n",
    "test_thermal_loader = DataLoader(test_thermal_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9280ef03-8e8f-4743-b14b-477da8ea1db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Evaluate the model on the test dataset\n",
    "test_predictions, test_targets = evaluate_model(thermal_model, test_thermal_loader, device)\n",
    "\n",
    "unique_labels = np.unique(labels)\n",
    "print(\"Unique labels:\", unique_labels)\n",
    "print(f\"Boxes: {boxes}\")\n",
    "print(f\"Labels: {labels}\")\n",
    "print(f\"Scores: {scores}\")\n",
    "print(f\"Number of images without annotations: {thermal_dataset.no_annotation_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254214f9-4be4-4092-85c0-5e9b058d3c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Visualize the object detection results\n",
    "def visualize_detections(image, boxes, labels, scores, class_labels, confidence_threshold=0.3):\n",
    "    image_with_detections = image.copy()\n",
    "    \n",
    "    height, width, _ = image.shape\n",
    "    \n",
    "    if not isinstance(boxes, (list, np.ndarray)):\n",
    "        boxes = [boxes]\n",
    "    \n",
    "    if not isinstance(labels, (list, np.ndarray)):\n",
    "        labels = [labels]\n",
    "    \n",
    "    if not isinstance(scores, (list, np.ndarray)):\n",
    "        scores = [scores]\n",
    "    \n",
    "    for box, label, score in zip(boxes, labels, scores):\n",
    "        if score >= confidence_threshold:\n",
    "            if isinstance(box, (list, np.ndarray)):\n",
    "                xmin, ymin, xmax, ymax = box\n",
    "            else:\n",
    "                xmin, ymin, xmax, ymax = box, box, box, box  \n",
    "            xmin = int(xmin * width)\n",
    "            ymin = int(ymin * height)\n",
    "            xmax = int(xmax * width)\n",
    "            ymax = int(ymax * height)\n",
    "            \n",
    "            class_name = class_labels[int(label)]  \n",
    "            \n",
    "            cv2.rectangle(image_with_detections, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "            cv2.putText(image_with_detections, f\"{class_name}: {score:.2f}\", (xmin, ymin - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "    \n",
    "    return image_with_detections\n",
    "\n",
    "num_visualizations = 50\n",
    "class_labels = {1: \"vehicle\"}\n",
    "\n",
    "for i in range(num_visualizations):\n",
    "    image_path = test_thermal_dataset.images[i]\n",
    "    image = cv2.imread(image_path)  \n",
    "    \n",
    "    boxes, labels, scores = test_predictions[i]\n",
    "    \n",
    "    print(f\"Boxes: {boxes}\")\n",
    "    print(f\"Labels: {labels}\")\n",
    "    print(f\"Scores: {scores}\")\n",
    "    \n",
    "    image_with_detections = visualize_detections(image, boxes, labels, scores, class_labels)\n",
    "    \n",
    "    cv2.imshow(f\"Thermal Object Detection - Image {i+1}\", image_with_detections)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4dd190-3e05-4ed6-8570-f075992cdde3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e539f537-3fdb-4293-846b-87fb33b28e53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
